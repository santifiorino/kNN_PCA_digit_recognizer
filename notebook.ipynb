{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import seaborn as sns\n",
    "import time\n",
    "from IPython.display import display, clear_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea los k folds (Por cada uno crea 3 csv's: Train, Test y Expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_k_folds(train, k):\n",
    "    train = train.sample(frac=1)\n",
    "    folds = []\n",
    "    for i in range(k):\n",
    "        folds.append(train[i*len(train)//k : (i+1)*len(train)//k])\n",
    "    for i in range(k):\n",
    "        \n",
    "        expected = pd.DataFrame().assign(label=folds[i]['label'])\n",
    "        expected.to_csv('./k-fold/expected_' + str(i) + '.csv', index=False)\n",
    "\n",
    "        new_test = folds[i]\n",
    "        new_test.drop(['label'], axis=1).to_csv('./k-fold/test_' + str(i) + '.csv', index=False)\n",
    "\n",
    "        new_train = pd.concat(folds[:i] + folds[i+1:])\n",
    "        new_train.to_csv('./k-fold/train_' + str(i) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corre el algoritmo de PCA para cada uno de los folds, por cada fold crea un csv: Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_PCA(folds, alpha, k):\n",
    "    for i in range(folds):\n",
    "        subprocess.run(['./PCA', f'./k-fold/pca/train_{i}.csv', f'./k-fold/pca/test_{i}.csv', f'./k-fold/pca/out_{i}.csv', str(alpha), str(k)], stdout=subprocess.PIPE, encoding='ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kNN(folds, k):\n",
    "    for i in range(folds):\n",
    "        subprocess.run(['./kNN', f'./k-fold/knn/train_{i}.csv', f'./k-fold/knn/test_{i}.csv', f'./k-fold/knn/out_{i}.csv', str(k)], stdout=subprocess.PIPE, encoding='ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 10\n",
    "create_k_folds(train, folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pecision, Recall, Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 4\n",
    "k_for_pca = 5\n",
    "run_PCA(folds, alpha, k_for_pca)\n",
    "k_for_knn = -1 # TODO falta buscar cual es el k optimo para knn\n",
    "run_kNN(folds, k_for_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(folds, method):\n",
    "    confusion = np.zeros((10, 10), dtype=int)\n",
    "    for i in range(folds):\n",
    "        out = pd.read_csv(f'./k-fold/{method}/out_{i}.csv')\n",
    "        expected = pd.read_csv(f'./k-fold/{method}/expected_{i}.csv')\n",
    "        for j in range(len(out)):\n",
    "            expected_label = int(expected.iloc[[j]]['label'])\n",
    "            predicted_label = int(out.iloc[[j]]['Label'])\n",
    "            confusion[expected_label][predicted_label] += 1\n",
    "    return confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(confusion):\n",
    "    TP = np.diag(confusion)\n",
    "    FP = np.sum(confusion, axis=0) - TP\n",
    "    FN = np.sum(confusion, axis=1) - TP\n",
    "    return TP/(TP+FP+FN)\n",
    "\n",
    "def get_precision(confusion):\n",
    "    TP = np.diag(confusion)\n",
    "    FP = np.sum(confusion, axis=0) - TP\n",
    "    return TP / (TP+FP)\n",
    "\n",
    "def get_recall(confusion):\n",
    "    TP = np.diag(confusion)\n",
    "    FN = np.sum(confusion, axis=1) - TP\n",
    "    return TP / (TP+FN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_pca = confusion_matrix(folds, 'pca')\n",
    "print(\"Accuracy:\", get_accuracy(confusion_pca))\n",
    "print(\"Precision:\", get_precision(confusion_pca))\n",
    "print(\"Recall:\", get_recall(confusion_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_knn = confusion_matrix(folds, 'knn')\n",
    "print(\"Accuracy:\", get_accuracy(confusion_knn))\n",
    "print(\"Precision:\", get_precision(confusion_knn))\n",
    "print(\"Recall:\", get_recall(confusion_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(confusion_pca, cmap='gray')\n",
    "plt.xticks(np.arange(0,10))\n",
    "plt.yticks(np.arange(0,10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(confusion_knn, cmap='gray')\n",
    "plt.xticks(np.arange(0,10))\n",
    "plt.yticks(np.arange(0,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kaggle_accuracy(sub, correct_answers):\n",
    "    count = 0\n",
    "    for i in range(len(sub)):\n",
    "        if int(sub.iloc[[i]]['Label']) == int(correct_answers.iloc[[i]]['Label']):\n",
    "            count += 1\n",
    "    return count / len(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle = pd.read_csv('kaggle.csv')\n",
    "\n",
    "alphas = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "ks = [1, 3, 5, 10, 25, 50]\n",
    "\n",
    "data = pd.DataFrame([], columns=['alpha', 'k', 'accuracy', 'time'])\n",
    "for alpha in alphas:\n",
    "    for k in ks:\n",
    "        time = subprocess.run(['./PCA', 'train.csv', 'test.csv', 'out.csv', str(alpha), str(k)], stdout=subprocess.PIPE, encoding='ascii').stdout.split('\\n')[0]\n",
    "        score = get_kaggle_accuracy(pd.read_csv('out.csv'), kaggle)\n",
    "        data = data.append({'alpha': alpha, 'k': k, 'accuracy': score, 'time': float(time)}, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=data, x=\"alpha\", y=\"accuracy\", hue=\"k\", aspect=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sns.relplot(data=data, x=\"alpha\", y=\"time\", hue=\"k\", kind=\"line\", aspect=1.5)\n",
    "p.set(xlabel='alpha', ylabel='time [seg]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El mejor es:\n",
    "column = data[\"accuracy\"]\n",
    "max_index = column.idxmax()\n",
    "data.iloc[[max_index]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle = pd.read_csv('kaggle.csv')\n",
    "\n",
    "ks = [1, 3, 5, 7, 9, 11, 13, 15, 20, 25, 30, 40, 50, 100]\n",
    "\n",
    "data = pd.DataFrame([], columns=['k', 'accuracy', 'time'])\n",
    "i = 0\n",
    "start = time.time()\n",
    "time_previous = 0\n",
    "for k in ks:\n",
    "    clear_output(wait=True)\n",
    "    display(f'kNN tiempos - Experimento: {i+1} / {len(ks)} - Tiempo (dataset): {time.time() - start} segs - Tiempo (Ãºltimo): {time_previous}')        \n",
    "    time_experiment = subprocess.run(['./kNN_tiempos', 'train.csv', 'test.csv', 'out.csv', str(k)], stdout=subprocess.PIPE, encoding='ascii').stdout.split('\\n')[0]\n",
    "    score = get_kaggle_accuracy(pd.read_csv('out.csv'), kaggle)\n",
    "    data = data.append({'k': k, 'accuracy': score, 'time': float(time)}, ignore_index = True)\n",
    "    time_previous = time_experiment\n",
    "    i += 1\n",
    "data.to_csv('knn_accuracy_time.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
